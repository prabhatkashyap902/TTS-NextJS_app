{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéôÔ∏è Qwen3-TTS API Server v7\n",
        "\n",
        "Voice Cloning (2K char limit, no chunking)"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "!pip install -q qwen-tts flask flask-cors pyngrok soundfile numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from qwen_tts import Qwen3TTSModel\n",
        "\n",
        "print(\"üîÑ Loading Qwen3-TTS model...\")\n",
        "print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "model = Qwen3TTSModel.from_pretrained(\n",
        "    \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\",\n",
        "    device_map=\"cuda:0\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model loaded!\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter ngrok token: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_TOKEN = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "from pyngrok import ngrok\n",
        "if NGROK_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "    print(\"‚úÖ ngrok token set!\")"
      ],
      "metadata": {
        "id": "ngrok_setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, send_file, jsonify, Response\n",
        "from flask_cors import CORS\n",
        "import soundfile as sf\n",
        "import io, base64, tempfile, os, json\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({\"status\": \"ok\", \"model\": \"Qwen3-TTS-1.7B\", \"version\": \"v7\", \"gpu\": torch.cuda.get_device_name(0)})\n",
        "\n",
        "@app.route('/api/tts', methods=['POST'])\n",
        "def generate_tts():\n",
        "    data = request.json\n",
        "    text = data.get('text', 'Hello')\n",
        "    language = data.get('language', 'English')\n",
        "    ref_audio_b64 = data.get('ref_audio')\n",
        "    ref_text = data.get('ref_text', '')\n",
        "    stream = data.get('stream', False)\n",
        "\n",
        "    def generate_with_progress():\n",
        "        try:\n",
        "            print(f\"üéôÔ∏è Gen: lang={language}, chars={len(text)}\")\n",
        "            \n",
        "            yield f\"data: {json.dumps({'type': 'progress', 'current': 0, 'total': 1, 'percent': 10, 'status': 'Loading reference audio...'})}\\n\\n\"\n",
        "            \n",
        "            # Decode reference audio (REQUIRED)\n",
        "            if not ref_audio_b64:\n",
        "                yield f\"data: {json.dumps({'type': 'error', 'message': 'Reference audio is required'})}\\n\\n\"\n",
        "                return\n",
        "            \n",
        "            audio_bytes = base64.b64decode(ref_audio_b64)\n",
        "            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:\n",
        "                f.write(audio_bytes)\n",
        "                temp_path = f.name\n",
        "            \n",
        "            yield f\"data: {json.dumps({'type': 'progress', 'current': 0, 'total': 1, 'percent': 30, 'status': 'Generating speech...'})}\\n\\n\"\n",
        "            \n",
        "            try:\n",
        "                if ref_text and ref_text.strip():\n",
        "                    wavs, sr = model.generate_voice_clone(text=text, language=language, ref_audio=temp_path, ref_text=ref_text)\n",
        "                else:\n",
        "                    wavs, sr = model.generate_voice_clone(text=text, language=language, ref_audio=temp_path, x_vector_only_mode=True)\n",
        "            finally:\n",
        "                os.unlink(temp_path)\n",
        "            \n",
        "            yield f\"data: {json.dumps({'type': 'progress', 'current': 1, 'total': 1, 'percent': 90, 'status': 'Encoding audio...'})}\\n\\n\"\n",
        "            \n",
        "            buffer = io.BytesIO()\n",
        "            sf.write(buffer, wavs[0], sr, format='WAV')\n",
        "            buffer.seek(0)\n",
        "            audio_b64 = base64.b64encode(buffer.read()).decode('utf-8')\n",
        "            \n",
        "            duration = len(wavs[0]) / sr\n",
        "            print(f\"‚úÖ Generated {duration:.2f}s of audio\")\n",
        "            \n",
        "            yield f\"data: {json.dumps({'type': 'complete', 'audio': audio_b64, 'duration': round(duration, 1)})}\\n\\n\"\n",
        "            \n",
        "        except Exception as e:\n",
        "            import traceback; traceback.print_exc()\n",
        "            yield f\"data: {json.dumps({'type': 'error', 'message': str(e)})}\\n\\n\"\n",
        "\n",
        "    if stream:\n",
        "        return Response(generate_with_progress(), mimetype='text/event-stream', headers={'Cache-Control': 'no-cache', 'Connection': 'keep-alive', 'X-Accel-Buffering': 'no'})\n",
        "    else:\n",
        "        # Non-streaming fallback\n",
        "        try:\n",
        "            if not ref_audio_b64:\n",
        "                return jsonify({\"error\": \"Reference audio is required\"}), 400\n",
        "            \n",
        "            audio_bytes = base64.b64decode(ref_audio_b64)\n",
        "            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:\n",
        "                f.write(audio_bytes)\n",
        "                temp_path = f.name\n",
        "            \n",
        "            try:\n",
        "                if ref_text and ref_text.strip():\n",
        "                    wavs, sr = model.generate_voice_clone(text=text, language=language, ref_audio=temp_path, ref_text=ref_text)\n",
        "                else:\n",
        "                    wavs, sr = model.generate_voice_clone(text=text, language=language, ref_audio=temp_path, x_vector_only_mode=True)\n",
        "            finally:\n",
        "                os.unlink(temp_path)\n",
        "\n",
        "            buffer = io.BytesIO()\n",
        "            sf.write(buffer, wavs[0], sr, format='WAV')\n",
        "            buffer.seek(0)\n",
        "            return send_file(buffer, mimetype='audio/wav', as_attachment=True, download_name='output.wav')\n",
        "        except Exception as e:\n",
        "            import traceback; traceback.print_exc()\n",
        "            return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/clone', methods=['POST'])\n",
        "def voice_clone():\n",
        "    return generate_tts()\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"üöÄ URL: {public_url}\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "id": "start_server"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
