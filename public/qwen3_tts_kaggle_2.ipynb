{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéôÔ∏è Qwen3-TTS for Kaggle (with Chunking)\n",
        "\n",
        "**Supports unlimited text** - splits into 2K chunks automatically!\n",
        "\n",
        "**Before running:**\n",
        "1. Settings ‚Üí Accelerator ‚Üí **GPU T4 x2**\n",
        "2. Settings ‚Üí Internet ‚Üí **ON**\n",
        "3. Run cells with **Shift+Enter** (one by one!)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q qwen-tts flask flask-cors pyngrok soundfile numpy"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from qwen_tts import Qwen3TTSModel\n",
        "\n",
        "print(\"üîÑ Loading Qwen3-TTS model...\")\n",
        "print(f\"   GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "model = Qwen3TTSModel.from_pretrained(\n",
        "    \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\",\n",
        "    device_map=\"cuda:0\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model loaded!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PASTE YOUR NGROK TOKEN HERE!\n",
        "NGROK_TOKEN = \"\"  # <-- Get from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "from pyngrok import ngrok\n",
        "if NGROK_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "    print(\"‚úÖ ngrok token set!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Enter your ngrok token above!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, send_file, jsonify, Response\n",
        "from flask_cors import CORS\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import io, base64, tempfile, os, json, re\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "CHUNK_SIZE = 2000  # Characters per chunk\n",
        "\n",
        "def split_text(text, max_chars=CHUNK_SIZE):\n",
        "    \"\"\"Split text into chunks at sentence boundaries\"\"\"\n",
        "    sentences = re.split(r'(?<=[.!?‡•§])\\s+', text)\n",
        "    chunks = []\n",
        "    current = \"\"\n",
        "    for s in sentences:\n",
        "        if len(current) + len(s) <= max_chars:\n",
        "            current += (\" \" if current else \"\") + s\n",
        "        else:\n",
        "            if current:\n",
        "                chunks.append(current.strip())\n",
        "            # If single sentence is too long, split by words\n",
        "            if len(s) > max_chars:\n",
        "                words = s.split()\n",
        "                current = \"\"\n",
        "                for word in words:\n",
        "                    if len(current) + len(word) + 1 <= max_chars:\n",
        "                        current += (\" \" if current else \"\") + word\n",
        "                    else:\n",
        "                        if current:\n",
        "                            chunks.append(current.strip())\n",
        "                        current = word\n",
        "            else:\n",
        "                current = s\n",
        "    if current:\n",
        "        chunks.append(current.strip())\n",
        "    return chunks if chunks else [text]\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({\"status\": \"ok\", \"model\": \"Qwen3-TTS-1.7B\", \"gpu\": torch.cuda.get_device_name(0), \"chunk_size\": CHUNK_SIZE})\n",
        "\n",
        "@app.route('/api/tts', methods=['POST'])\n",
        "def generate_tts():\n",
        "    data = request.json\n",
        "    text = data.get('text', 'Hello')\n",
        "    language = data.get('language', 'English')\n",
        "    ref_audio_b64 = data.get('ref_audio')\n",
        "    ref_text = data.get('ref_text', '')\n",
        "    stream = data.get('stream', False)\n",
        "\n",
        "    def generate_with_progress():\n",
        "        try:\n",
        "            if not ref_audio_b64:\n",
        "                yield f\"data: {json.dumps({'type': 'error', 'message': 'Reference audio is required'})}\\n\\n\"\n",
        "                return\n",
        "            \n",
        "            # Split text into chunks\n",
        "            chunks = split_text(text, CHUNK_SIZE)\n",
        "            total_chunks = len(chunks)\n",
        "            \n",
        "            print(f\"üéôÔ∏è Generating: {len(text)} chars ‚Üí {total_chunks} chunks\")\n",
        "            \n",
        "            yield f\"data: {json.dumps({'type': 'progress', 'current': 0, 'total': total_chunks, 'percent': 0, 'status': f'Preparing {total_chunks} chunks...'})}\\n\\n\"\n",
        "            \n",
        "            # Decode reference audio\n",
        "            audio_bytes = base64.b64decode(ref_audio_b64)\n",
        "            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:\n",
        "                f.write(audio_bytes)\n",
        "                ref_path = f.name\n",
        "            \n",
        "            yield f\"data: {json.dumps({'type': 'progress', 'current': 0, 'total': total_chunks, 'percent': 5, 'status': 'Reference audio loaded'})}\\n\\n\"\n",
        "            \n",
        "            all_audio = []\n",
        "            sample_rate = None\n",
        "            \n",
        "            for i, chunk in enumerate(chunks):\n",
        "                pct = int(((i) / total_chunks) * 90) + 5\n",
        "                yield f\"data: {json.dumps({'type': 'progress', 'current': i, 'total': total_chunks, 'percent': pct, 'status': f'Generating chunk {i+1}/{total_chunks}...'})}\\n\\n\"\n",
        "                \n",
        "                try:\n",
        "                    if ref_text and ref_text.strip():\n",
        "                        wavs, sr = model.generate_voice_clone(text=chunk, language=language, ref_audio=ref_path, ref_text=ref_text)\n",
        "                    else:\n",
        "                        wavs, sr = model.generate_voice_clone(text=chunk, language=language, ref_audio=ref_path, x_vector_only_mode=True)\n",
        "                    \n",
        "                    all_audio.append(wavs[0])\n",
        "                    if sample_rate is None:\n",
        "                        sample_rate = sr\n",
        "                except Exception as chunk_err:\n",
        "                    print(f\"‚ùå Chunk {i+1} failed: {chunk_err}\")\n",
        "                    yield f\"data: {json.dumps({'type': 'error', 'message': f'Chunk {i+1} failed: {str(chunk_err)}'})}\\n\\n\"\n",
        "                    return\n",
        "                \n",
        "                pct = int(((i + 1) / total_chunks) * 90) + 5\n",
        "                yield f\"data: {json.dumps({'type': 'progress', 'current': i + 1, 'total': total_chunks, 'percent': pct, 'status': f'Chunk {i+1}/{total_chunks} done'})}\\n\\n\"\n",
        "            \n",
        "            # Cleanup ref audio\n",
        "            os.unlink(ref_path)\n",
        "            \n",
        "            yield f\"data: {json.dumps({'type': 'progress', 'current': total_chunks, 'total': total_chunks, 'percent': 95, 'status': 'Concatenating audio...'})}\\n\\n\"\n",
        "            \n",
        "            # Concatenate all audio chunks\n",
        "            final_audio = np.concatenate(all_audio)\n",
        "            \n",
        "            buffer = io.BytesIO()\n",
        "            sf.write(buffer, final_audio, sample_rate, format='WAV')\n",
        "            buffer.seek(0)\n",
        "            audio_b64 = base64.b64encode(buffer.read()).decode('utf-8')\n",
        "            \n",
        "            duration = len(final_audio) / sample_rate\n",
        "            print(f\"‚úÖ Generated {duration:.1f}s from {total_chunks} chunks\")\n",
        "            \n",
        "            yield f\"data: {json.dumps({'type': 'complete', 'audio': audio_b64, 'duration': round(duration, 1), 'chunks': total_chunks})}\\n\\n\"\n",
        "            \n",
        "        except Exception as e:\n",
        "            import traceback; traceback.print_exc()\n",
        "            yield f\"data: {json.dumps({'type': 'error', 'message': str(e)})}\\n\\n\"\n",
        "\n",
        "    if stream:\n",
        "        return Response(generate_with_progress(), mimetype='text/event-stream', headers={'Cache-Control': 'no-cache', 'X-Accel-Buffering': 'no'})\n",
        "    else:\n",
        "        # Non-streaming fallback\n",
        "        try:\n",
        "            if not ref_audio_b64:\n",
        "                return jsonify({\"error\": \"Reference audio is required\"}), 400\n",
        "            \n",
        "            audio_bytes = base64.b64decode(ref_audio_b64)\n",
        "            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:\n",
        "                f.write(audio_bytes)\n",
        "                ref_path = f.name\n",
        "            \n",
        "            chunks = split_text(text, CHUNK_SIZE)\n",
        "            all_audio = []\n",
        "            sample_rate = None\n",
        "            \n",
        "            for chunk in chunks:\n",
        "                if ref_text and ref_text.strip():\n",
        "                    wavs, sr = model.generate_voice_clone(text=chunk, language=language, ref_audio=ref_path, ref_text=ref_text)\n",
        "                else:\n",
        "                    wavs, sr = model.generate_voice_clone(text=chunk, language=language, ref_audio=ref_path, x_vector_only_mode=True)\n",
        "                all_audio.append(wavs[0])\n",
        "                if sample_rate is None:\n",
        "                    sample_rate = sr\n",
        "            \n",
        "            os.unlink(ref_path)\n",
        "            final_audio = np.concatenate(all_audio)\n",
        "            \n",
        "            buffer = io.BytesIO()\n",
        "            sf.write(buffer, final_audio, sample_rate, format='WAV')\n",
        "            buffer.seek(0)\n",
        "            return send_file(buffer, mimetype='audio/wav')\n",
        "        except Exception as e:\n",
        "            return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/clone', methods=['POST'])\n",
        "def voice_clone():\n",
        "    return generate_tts()\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"üöÄ QWEN3-TTS URL: {public_url}\")\n",
        "print(f\"   Chunk size: {CHUNK_SIZE} chars\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "app.run(port=5000)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
